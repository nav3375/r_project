---
title: "London Marathon Data Analysis"
subtitle: "Team 6"
author: "Longxiang Wu, Navpreet Singh Sandhu, Shengle Yan, Ranjith Kumar Subramaniyan "
output:
  html_document:
    code_folding: hide
date: "2023-12-13"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(dplyr)
library(gridExtra)
library(forecast)
remotes::install_github("nrennie/LondonMarathon")
data(winners, package = "LondonMarathon")
data(london_marathon, package = "LondonMarathon")

```


# Project outline {.tabset}

## Introduction

## The London Marathon

The London Marathon, or the TCS London Marathon, is a truly special event that brings people from all walks of life together. It was the brainchild of visionaries Chris Brasher and John Disley back in 1981 and has since become the UK's second-largest annual road race, second only to the famous Great North Run in Newcastle.

Usually happening in April, the marathon had a temporary switch to October in 2020, 2021, and 2022 due to the challenges posed by the COVID-19 pandemic. The course itself is known for its mostly flat terrain, winding its way around the beautiful River Thames, starting at Blackheath and ending with a grand finish at The Mall.

But the London Marathon isn't just a race; it's a melting pot of experiences. There's the mass race, where people of all fitness levels challenge themselves and relish the thrill of completing a marathon. For elite long-distance runners, both men and women, there are professional races showcasing top-tier athleticism. Wheelchair races provide a platform for elite-level competition among both men and women.

What truly sets the London Marathon apart is its heartwarming philanthropic side. Participants aren't just running for personal glory; they're making a difference. Since its start, the marathon has raised over £1 billion for various charities. In 2019 alone, an incredible £66.4 million was raised, marking it as the highest single-day fundraising event in the marathon's history.

**How was it collected?**

The data seems to have been collected over the years, possibly sourced from official records, the official website of the London Marathon, event organizers, media outlets such as BBC, and other reliable sources associated with the event. The information could have been compiled from participant registrations, event statistics, official reports, and media coverage.




**For more details**:

<https://en.wikipedia.org/wiki/London_Marathon>


Now, let's dive into the details of the marathon with the comprehensive data:

<hr style="border: 2px solid black;">

### **Data Wrangling**

**Winners Data**
```{r}
#remotes::install_github("nrennie/LondonMarathon")
data(winners, package = "LondonMarathon")
head(winners)
```

**London Marathon Data**
```{r}
data(london_marathon, package = "LondonMarathon")
head(london_marathon)
```



There are two datasets in this "LondonMarathon" package.

The first dataset records information about London Marathon winners over the years. Each entry includes five variables: the winner’s category, race year, athlete name, athlete nationality, and race time.

The second dataset records information about London Marathon events over the years. Each entry contains details such as the event date, year, the number of applicants, accepted participants, starters, finishers, the name of the official charity sponsoring the event, and the sponsorship amount.

### Key Aspects

**Cases:** Each row in the datasets represents a specific year of the London Marathon. There are 42 entries in the "London Marathon Data" and 165 entries in the "Winners Data".

### Variables in London Marathon Data:

- **Date:** Reflecting the date of the London Marathon.
- **Year:** Indicating the corresponding year of the London Marathon.
- **Applicants:** The count of individuals applying to participate in the marathon.
- **Accepted:** The number of applicants who secured a spot to participate.
- **Starters:** The count of participants who initiated the marathon.
- **Finishers:** The number of participants successfully completing the marathon.
- **Raised:** The total amount of money raised during the marathon.
- **Official Charity:** The designated charity associated with the marathon for that specific year.

### Variables in Winner Data:

- **Category:** Specifies the category of the winner (Men, Women, Wheelchair Men, Wheelchair Women).
- **Year:** Denoting the year when the London Marathon took place.
- **Athlete:** The name of the winning athlete.
- **Nationality:** The country of origin of the winning athlete.
- **Time:** The duration taken by the winning athlete to complete the marathon.


## Data Wrangling

As the datasets are different aspects of information about london marathon, we choose not to combine them but analyze them seperately.


#### Which subset of the data is relevant to our research question? Have we filtered out any observations from the analysis? Have we created new variables?
For the winners dataset, all variables and observations are relevant. For the london_marathon dataset, only variables Year, Applicants, Accepted, Starters, Finishers are relevant to our research questions.  

For the winners dataset, no observation is filtered out. For the london_marathon dataset, we filtered out the observation in year 2020-2022.  

We created new variables, which are ratio of accepted, ratio of starters, and ratio of finishers, in the london_marathon dataset.

### Methods dealing with missing values
1. Deleting
2. Interpolation
- mean, median, mode
- KNN(K nearest neighbor)
- stochastic interpolation
- EM
- Lagrange interpolation
- Hot-Deck imputation
3. Multiple Interpolation
- Predictive Mean Matching
- Propensity Score
- Markov Chain Monte Carlo
4. Models
- Regression
- Bayesian models
- Random Forest
- Decision Tree
5. Mapping to higher dimensions
6. Stochastic filling
- Bayesian bootstrap
- Approximate Bayesian Bootstrap
7. Not dealing with

We chose not dealing with the missing values, in london_marathon dataset. The reason is that those values are missing systematically. No appropriate methods are candidates until we figured out why they are missing, which is beyond our capability.


### Do variables have appropriate type?
Here is the data types summary. 

```{r}
library(knitr)
table <- data.frame('Column'=c('Category','Year','Athlete','Nationality','Time'), 'Class'=c('character','integer','character','character','character'), 'Description'=c('Category of race','Year','Name of the winner','Nationality of the winner','Winning time'),'Example'=c('Men',1981,'Dick Beardsley(Tie)','United States', '02:11:48'))
kable(table, caption = "Winners")
table2 <- data.frame('Column'=c('Date','Year','Applicants','Accepted','Starters','Finishers','Raised','Official.charity'),'Class'=c('character','integer','integer','integer','integer','integer','integer','character'),'Description'=c('Date of the race','Year','Number of people who applied','Number of people accepted','Number of people who started','Number of people who finished','Amount raised for charity(£ millions)','Official charity'),'Example'=c('1981-03-29','1981','20000','7747','7055','6255','46.5','SportsAid'))
kable(table2, caption = "London Marathon")
```

### Are there any strange aspects to the data?
In the london_marathon dataset, observation of number of applicants in year 1981-2012 are in a unit of 1000. And observations of number of applicants, accepted, starters, and finishers in year 2020 are abnormally low.



## Winners(analysis & conclusions)

### Anlysis of winners dataset
Overview of the dataset
```{r}
head(winners)
```

#### Trends in winning times over the year
```{r}
winners_data <- winners |> mutate(Time=24*Time)

winners_data$Year <- as.numeric(winners_data$Year)
winners_data$Time <- as.numeric(winners_data$Time)

# Create time series plots for all categories with captions
ggplot(winners_data, aes(x = Year, y = Time, color = Category)) +
  geom_line() +
  ggtitle("Time Trends - All Categories") +
  xlab("Year") +
  ylab("Winning Time (in hours)") +
  labs(caption = "Figure 1: Time trends in winning times for different categories over the years.")
```
Men and Women:

Both Men and Women categories show a relatively linear trend over the years. For Men, the winning time decreases from around 0.09 to 0.08, indicating a consistent improvement in performance. Similarly, for Women, the winning time decreases from approximately 0.104 to 0.096, suggesting a trend of faster winning times.

Wheelchair Men and Wheelchair Women:

The plot reveals a substantial drop in winning times for both Wheelchair Men and Wheelchair Women over the years. Wheelchair Men’s winning time decreases from 0.1389 to 0.06, indicating a significant performance improvement. Wheelchair Women’s winning time also decreases from 0.1868 to 0.069, reflecting a substantial and consistent improvement.

The overall trend suggests that there has been an improvement in athletic performance across all categories over the years, with notable drops in winning times.

#### Compare winning times between different categories (i.e. How much difference there is between performance of men and women?)

```{r}
boxplot(Time ~ Category, data = winners_data, desc= T,main="Boxplots of Winning Time of Each Category")
```

From this plot, we can see there is difference of performance between men and women.


```{r}
# t-test for Men vs. Women
t_test_men_women <- t.test(Time ~ Category, data = subset(winners_data, Category %in% c("Men", "Women")))
print(t_test_men_women)
```
t-value: The t-value of -21.25 is highly significant. It indicates that the difference in mean finishing times between Men and Women is substantial, and it is unlikely to be due to random chance. The negative sign suggests that, on average, Men finish the marathon faster than Women.

Degrees of Freedom: The degrees of freedom are approximately 69.816, calculated using Welch’s correction for unequal variances.

Hypotheses:

Null Hypothesis (H0): The mean winning time for Men is equal to the mean winning time for Women. μ(Men) = μ(Women)

Alternative Hypothesis (H1): The mean winning time for Men is different from the mean winning time for Women. μ(Men) ≠ μ(Women)

p-value: The p-value is extremely small (< 2.2e-16), indicating strong evidence against the null hypothesis. A low p-value indicates that the observed difference in mean winning times between Men and Women is highly unlikely to be due to random chance.

Confidence Interval: The 95% confidence interval (-0.01194160 to -0.00989228) provides a range where the true difference in mean finishing times between Men and Women is likely to be found. Since this range doesn’t include zero, it supports the idea that there is a significant difference.

Sample Estimates: The mean winning time for Men (0.08837516) is significantly different from the mean winning time for Women (0.09929210).

Conclusion: Given the very low p-value, we reject the null hypothesis. There is strong statistical evidence to suggest that there is a significant difference in mean winning times between Men and Women. The negative mean difference in the confidence interval indicates that, on average, Men have a lower winning time compared to Women.

```{r}
# t-test for Wheelchair Men vs. Wheelchair Women
t_test_wheelchair <- t.test(Time ~ Category, data = subset(winners_data, Category %in% c("Wheelchair Men", "Wheelchair Women")))
print(t_test_wheelchair)
```
t-value: The t-value is -3.684, indicating a substantial difference between the mean winning times of Wheelchair Men and Wheelchair Women. The negative sign suggests that, on average, Wheelchair Women have a higher winning time.

Degrees of Freedom (df): The degrees of freedom are 66.574, calculated using Welch’s method.

Null Hypothesis (H0): The mean winning times for Wheelchair Men and Wheelchair Women are equal. Alternative Hypothesis (HA): The mean winning times for Wheelchair Men and Wheelchair Women are not equal.

p-value = 0.0004625: The p-value is less than 0.05, indicating that there is strong evidence to reject the null hypothesis.

95 percent confidence interval: The range -0.025672067 to -0.007628028 represents the range within which we can be 95% confident that the true difference in means lies. In this case, it suggests that the mean winning time for Wheelchair Women is likely to be between 0.0076 and 0.0256 higher than that of Wheelchair Men.

With a small p-value and a negative t-value, there is evidence to suggest that there is a statistically significant difference in winning times between Wheelchair Men and Wheelchair Women. The mean winning time for Wheelchair Women appears to be significantly higher than that for Wheelchair Men. The 95% confidence interval provides a range for the magnitude of this difference.

```{r}
# ANOVA for Men vs. Women vs. Wheelchair Men vs. Wheelchair Women
anova_model <- aov(Time ~ Category, data = subset(winners_data, Category %in% c("Men", "Women", "Wheelchair Men", "Wheelchair Women")))
summary(anova_model)
```
Null Hypothesis (H0): There is no significant difference in mean winning times among the categories.

Alternative Hypothesis (H1): There is a significant difference in mean winning times among at least one pair of categories.

I reject the null hypothesis, concluding that there are significant differences in mean winning times across at least one pair of categories (Men, Women, Wheelchair Men, Wheelchair Women).

F-Test: The F value of 24.34 is higher than expected by chance, signifying significant differences in mean winning times among categories.

p-value: With a tiny p-value (4.81e-13), there is substantial evidence against the null hypothesis, implying significant differences in mean winning times.

#### Explore potential correlations between winning times and other variables
```{r}
# Explore potential correlations between winning times and other variables.

# Convert 'Nationality' to a factor variable
winners_data$Nationality <- as.factor(winners_data$Nationality)

# Calculate correlation coefficients
cor_year_time <- cor(winners_data$Year, winners_data$Time, method = "pearson")
cor_nat_time <- cor(as.numeric(winners_data$Nationality), winners_data$Time, method = "spearman")

print(paste("Correlation between Year and Time (Pearson):", cor_year_time))
print(paste("Correlation between Nationality and Time (Spearman):", cor_nat_time))
```
We observed a correlation between Year and Time (Pearson) of -0.4648, indicating a moderate negative linear relationship. As the Year increases, the Time tends to decrease moderately. The closer the correlation coefficient is to -1, the stronger the negative linear relationship.

Furthermore, the correlation between Nationality and Time (Spearman) is -0.1314, suggesting a weak negative monotonic relationship. As the ranks of Nationality increase, the Time tends to decrease weakly. The closer the Spearman correlation coefficient is to -1, the stronger the negative monotonic relationship.

##### Test whether there is difference of athletes' performance based on nationality
Here, the null hypothesis is that $H_0$: there is no difference of athletes' performance based on nationality. The alternative hypothesis is that $H_A$: there is difference of athletes' performance based on nationality.


###### Anova test
```{r}
winners_data$Time <- as.numeric(winners_data$Time)

# Performing ANOVA
anova_model <- aov(Time ~ Nationality, data = winners_data)
anova_summary <- summary(anova_model)

# Print ANOVA summary
print(anova_summary)
```

###### Kruskal-Wallis test
```{r}
# In case the assumptions of ANOVA are not met, use Kruskal-Wallis test as a non-parametric alternative
kruskal_test <- kruskal.test(Time ~ Nationality, data = winners_data)
print(kruskal_test)
```

Here we can see that both test give a p-value that is close to 0. So there is evidence to reject the null hypothesis, and we conclude that there is difference of athletes' performance based on nationality.

#### Summarize which country has the most winners based on category
```{r,warning=FALSE,message=FALSE}
winners_data |> group_by(Category,Nationality) |> summarise(count = n()) |> arrange(desc(count)) |> slice_head()

```


## Marathon(analysis & conclusions)
Overview of the dataset
```{r}
head(london_marathon)
```

```{r}
cat("missing value count:", sum(is.na(london_marathon)))
```

```{r}
missing_percentage <- colMeans(is.na(london_marathon)) * 100
plot_data <- data.frame(
  variable = names(missing_percentage),
  percentage = missing_percentage
)
ggplot(plot_data, aes(x = variable, y = percentage)) +
  geom_bar(stat = "identity", fill = "skyblue", width = 0.5) +
  labs(title = "Percentage of missing values in London Marathon", y = "Percentage") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We can see that there are some missing values regarding the London Marathon.

the Raised means amount raised for charity (£ millions), and the Official charity means Official charity.

So we can think that if Official charity is NULL, it means there is no Official charity, then Raised should be 0 (or remove these values when analyzing Raised). If Official charity is not empty, and Raised is empty, then Raised is Non-public, then we can fill it in using the average of other data.

For the missing other fields, we can see that the fields are the same. According to the official documentation (Github), the data for the last two years is missing, so we should filter out the data for these two year (about london_marathon).

```{r}
london_marathon1 <- london_marathon %>% group_by(`Official charity`) %>% mutate(Raised=ifelse(is.na(Raised) & !is.na(`Official charity`), mean(london_marathon$Raised, na.rm=T), Raised))

london_marathon1 <- london_marathon1 %>% mutate(Raised=ifelse(is.na(`Official charity`), 0, Raised))

london_marathon1 <- london_marathon1 %>% mutate(`Official charity`=ifelse(is.na(`Official charity`), "None", `Official charity`))

london_marathon1 <- london_marathon1 %>% filter(Year < max(london_marathon1$Year) - 1)

cat("new missing value count:", sum(is.na(london_marathon1)))
```


```{r}
ggplot(london_marathon1, aes(x = Year, y = Raised)) +
  geom_line() +
  labs(title = "Raised Over the Years in London Marathon",
       x = "Year",
       y = "Raised") +
  theme_minimal()
```

From the line chart, we can see that the Raised data we filled is not helpful in analyzing the changes in Raised data. If we want to analyze the changes in this part, we only need to focus on the data from 2007 to 2019.

```{r}
filter_data <- london_marathon1 %>% filter(Year >= 2007 & Year <= 2019)
```


```{r}
ggplot(filter_data, aes(x=Year, y=Raised, group=1))+
  geom_line() + 
  geom_point() + 
  labs(title = "Raised Over the Years (2007-2019)",
     x = "Year",
     y = "Raised") +
  theme()
```
It can be seen that fundraising increases every year.
Now, we assume that raised is related to the year and other people counting information.
```{r}
selected_data <- filter_data %>% ungroup() %>%
  select(Year, Applicants, Accepted, Starters, Finishers, Raised)

# Build a linear regression model
linear_model <- lm(Raised ~ Year + Applicants + Accepted + Starters + Finishers, data = selected_data)

# Print a summary of the model
summary(linear_model)
```

The estimate of Year in the linear regression model for Raised is 1.054e+00, which is a positive coefficient, indicating that the amount of funds raised over the years has been on an upward trend. The overall model seems to suggest a positive relationship between the year and fundraising amounts, indicating an increasing trend over time. And the coefficients for the number of applicants, accepted participants, starters, and finishers are not statistically significant. This suggests that, based on the current model, these variables may not have a significant impact on fundraising amounts.

It can be seen from this plot that the winning time of men and women in wheelchairs has become significantly faster, while the winning time of normal men and women has gradually become faster, indicating that people are gradually paying attention to the competitiveness of marathon sports.

```{r}
# london marathon plot
london_plot <- london_marathon %>%
  filter(Year < 2020) %>%
  mutate(Year = factor(Year))

ggplot(
  data = london_plot,
  mapping = aes(y = Year)
) +
  geom_point(aes(x = Starters),
    colour = "#008080"
  ) +
  geom_point(aes(x = Finishers),
    colour = "#800080"
  ) +
  geom_segment(aes(
    x = Starters,
    xend = Finishers,
    y = Year,
    yend = Year
  )) +
  labs(
    x = "Number of runners",
    title = "Number of London Marathon Starters and Finishers"
  ) +
  theme_minimal() +
  theme(
    axis.title.y = element_blank(),
    plot.background = element_rect(fill = "white", colour = "white"),
    panel.background = element_rect(fill = "white", colour = "white")
  )
```


### Trends in number of applicants, accepted, starters, and finishers over year
```{r}
par(mfrow=c(2,2))
sub_london <- london_marathon[1:39,]
p1 <- ggplot(data= sub_london, aes(x=Year, y=Applicants ))+geom_point()+geom_line()+
  labs(title = "Applicants")
p2 <- ggplot(data= sub_london, aes(x=Year, y=Accepted ))+geom_point()+geom_line()+
  labs(title = "Accepted")
p3 <- ggplot(data= sub_london, aes(x=Year, y=Starters ))+geom_point()+geom_line()+
  labs(title = "Starters")
p4 <- ggplot(data= sub_london, aes(x=Year, y=Finishers))+geom_point()+geom_line()+
  labs(title = "Finishers")
grid.arrange(p1, p2, p3, p4, nrow=2, ncol=2)
```

### Analyze the dataset using linear models
In this part, we will use linear models to fit the data and predict the number of applicants, accepted, starters, and finishers in year 2024. 

From the previous part, we can see that the number of accepted, starters, and finishers versus year are generally linear. So the models we will use are $$y_i=\beta_0+\beta_1x_i+\epsilon_i, \quad \epsilon_i \sim N(0,\sigma^2)$$
For number of applicants, the model we we will use is $$y_i=\beta_0+\beta_1x_i+\beta_2x_i^2+\beta_3x_i^3+\epsilon_i, \quad \epsilon_i \sim N(0,\sigma^2)$$

Moreover, we will check the normality of the residuals.

```{r, include=FALSE}
hooks = knitr::knit_hooks$get()
hook_foldable = function(type) {
  force(type)
  function(x, options) {
    res = hooks[[type]](x, options)
    
    if (isFALSE(options[[paste0("fold.", type)]])) return(res)
    
    paste0(
      "<details><summary>", type, "</summary>\n\n",
      res,
      "\n\n</details>"
    )
  }
}
knitr::knit_hooks$set(
  output = hook_foldable("output"),
  plot = hook_foldable("plot")
)
```

#### For the number of applicants
```{r, fold.output=FALSE, fold.plot=FALSE}
fit1 <- lm(Applicants ~ Year + I(Year^2)+ I(Year^3), data = sub_london)
ggplot(sub_london, aes(x = Year, y = Applicants)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", formula = y ~ poly(x, 3), se = FALSE, color = "blue") +
  theme_minimal() +
  labs(title = "Polynomial Regression Model", x = "Year", y = "Number of Applicants")
```

##### Prediction

```{r}
new <- data.frame('Year'= 2024)
predict(fit1, newdata = data.frame(new), interval = c("confidence"), level = 0.95, type="response")
```

The number of applicants is estimated to be 571826 in 2024. A $95\%$ prediction interval is $(498633, 645018)$.

##### Model Checking
```{r}
plot(fit1, which=1)
plot(fit1, which=2)
```


#### For the number of accepted 

```{r, fold.output=FALSE, fold.plot=FALSE}
fit2 <- lm(Accepted ~ Year, data = sub_london)
ggplot(sub_london, aes(x = Year, y = Accepted)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", formula = 'y ~ x',se = FALSE, color = "blue") +
  theme_minimal() +
  labs(title = "SLR Model for Accepted", x = "Year", y = "Number of Accepted")
```
##### Prediction

```{r}
new <- data.frame('Year'= 2024)
predict(fit2, newdata = data.frame(new), interval = c("confidence"), level = 0.95, type="response")
```

The number of applicants is estimated to be 63762 in 2024. A $95\%$ prediction interval is $(60926, 66599)$.


##### Model Checking
```{r}
plot(fit2, which=1)
plot(fit2, which=2)
```


#### For the number of starters
```{r, fold.output=FALSE, fold.plot=FALSE}
fit3 <- lm(Starters ~ Year, data = sub_london)
ggplot(sub_london, aes(x = Year, y = Starters)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm", formula = 'y ~ x',se = FALSE, color = "blue") +
  theme_minimal() +
  labs(title = "SLR Model for Starters", x = "Year", y = "Number of Starters")

```
##### Prediction

```{r}
new <- data.frame('Year'= 2024)
predict(fit3, newdata = data.frame(new), interval = c("confidence"), level = 0.95, type="response")
```

The number of applicants is estimated to be 46119 in 2024. A $95\%$ prediction interval is $(44331, 47907)$.


##### Model Checking
```{r}
plot(fit3, which=1)
plot(fit3, which=2)
```


#### For the number of finishers
```{r, fold.output=FALSE, fold.plot=FALSE}
fit4 <- lm(Finishers ~ Year, data = sub_london)
ggplot(sub_london, aes(x = Year, y = Finishers)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm",formula = 'y ~ x', se = FALSE, color = "blue") +
  theme_minimal() +
  labs(title = "SLR Model for Finishers", x = "Year", y = "Number of Finishers")
```

##### Prediction

```{r}
new <- data.frame('Year'= 2024)
predict(fit4, newdata = data.frame(new), interval = c("confidence"), level = 0.95, type="response")
```

The number of applicants is estimated to be 46056 in 2024. A $95\%$ prediction interval is $(44306, 47807)$.


##### Model Checking
```{r}
plot(fit4, which=1)
plot(fit4, which=2)
```



### Create new variables and visulization
Let $x$ denote the number of applicants in a year, $y_1$ the number of accepted in a year, $y_2$ the number of starters in a year, $y_3$ the number of finishers in a year. We define the ratio of accepted as $r_1=\frac{y_1}{x}$, ratio of starters as $r_2=\frac{y_2}{y_1}$, ratio of finishers as  $r_3=\frac{y_3}{y_2}$.

```{r, fold.output=FALSE, fold.plot=FALSE}
london_marathon <- london_marathon |> mutate(`Ratio of Accepted`=Accepted/Applicants)|>mutate(`Ratio of Starters`=Starters/Accepted)|> mutate(`Ratio of Finishers`=Finishers/Starters)
print(london_marathon[, c("Year", "Ratio of Accepted", "Ratio of Starters","Ratio of Finishers")])


```

Accepted to Started: Over the years, there is a general trend of a decline in the percentage of accepted participants who actually start the race.

Started to Finished:

The percentage of starters who finish the race seems to be relatively stable, generally ranging from the high 80s to mid-90s.

Notable Observation (2020):

In 2020, there’s a notable observation in the “Accepted to Started” column. The percentage is 100%, indicating that all accepted participants started the race. However, the “Started to Finished” percentage is lower (79.22%), indicating that not all starters completed the race.

This discrepancy could be due to the impact of external factors such as the COVID-19 pandemic, leading to a different pattern in that particular year.

```{r, fold.output=FALSE, fold.plot=FALSE}
sub_london1 <- london_marathon[1:39,]
p1 <- ggplot(data= sub_london1, aes(x=Year, y=`Ratio of Accepted` ))+geom_point()+geom_line()+
  labs(title = "Ratio of Accepted")
p2 <- ggplot(data= sub_london1, aes(x=Year, y=`Ratio of Starters` ))+geom_point()+geom_line()+
  labs(title = "Ratio of Starters")
p3 <- ggplot(data= sub_london1, aes(x=Year, y=`Ratio of Finishers` ))+geom_point()+geom_line()+
  labs(title = "Ratio of Finishers")
grid.arrange(p1, p2, p3, ncol=1)
```

### Time series analysis and forecasting
In this part, we will focus on four time series, which are number of applicants each year, ratio of accepted each year, ratio of starters each year, and ratio of finishers each year. We will use ARIMA(AutoRegressive Integrated Moving Average) model to analyze and make forecasts for the time series in London marathon dataset. For each time series, we will draw a forecasting plot of 10 years, check the autocorrelation function of the residuals, check the normality of the residuals, and do a Box-Ljung test(a statistical test used to check whether any of a group of autocorrelations of a time series are different from zero).



```{r}
# a function to plot the forecast errors
plotForecastErrors <- function(forecasterrors)
  {
     # make a histogram of the forecast errors:
     mybinsize <- IQR(forecasterrors)/4
     mysd   <- sd(forecasterrors)
     mymin  <- min(forecasterrors) - mysd*5
     mymax  <- max(forecasterrors) + mysd*3
     # generate normally distributed data with mean 0 and standard deviation mysd
     mynorm <- rnorm(10000, mean=0, sd=mysd)
     mymin2 <- min(mynorm)
     mymax2 <- max(mynorm)
     if (mymin2 < mymin) { mymin <- mymin2 }
     if (mymax2 > mymax) { mymax <- mymax2 }
     # make a red histogram of the forecast errors, with the normally distributed data overlaid:
     mybins <- seq(mymin, mymax, mybinsize)
     hist(forecasterrors, col="red", freq=FALSE, breaks=mybins)
     # freq=FALSE ensures the area under the histogram = 1
     # generate normally distributed data with mean 0 and standard deviation mysd
     myhist <- hist(mynorm, plot=FALSE, breaks=mybins)
     # plot the normal curve as a blue line on top of the histogram of forecast errors:
     points(myhist$mids, myhist$density, type="l", col="blue", lwd=2)
}
```


#### Analysis of number of applicants 

##### Forecasting the number of applicants in next 10 years

```{r, fold.output=FALSE, fold.plot=FALSE}
app <- london_marathon$Applicants[1:40]
appts <- ts(app, ,frequency=1,start=1981)
appts <- na.omit(appts)

# fit the an automatic arima model
apptsarima <- auto.arima(appts)
# make forcast about the number of applicants in 10 years
fc <- forecast(apptsarima, h=10)
plot(fc, xlab = "Year", ylab= "Number of Applicants", main = "Forecasts of Number of Applicants")
```

The forecasting plot shows that there will be about 6000 annual increase of number of applicants for London marathon in the next 10 years.  

##### Checking ACF of the residuals

```{r}
# check autocorrelation function with lag from 1 to 20
acf(fc$residuals, lag.max=20,main="ACF Check for Resisuals")
```

##### Box-Ljung test for residuals

```{r}
# Box-Ljung test
Box.test(fc$residuals, lag=20, type="Ljung-Box")
```


##### Checking normality of the residuals

```{r}
# histogram of forecasterrors
plotForecastErrors(fc$residuals)
```

#### Analysis of ratio of accepted 

##### Forecasting ratio of accepted in next 10 years
```{r, fold.output=FALSE, fold.plot=FALSE}
roa <- london_marathon$`Ratio of Accepted`
roats <- ts(roa, ,frequency=1,start=1981)
roats<- na.omit(roats)

# fit the an automatic arima model
roatsarima <- auto.arima(roats)
# make forcast about the number of applicants in 10 years
fc2 <- forecast(roatsarima, h=10)
plot(fc2,xlab = "Year", ylab= "Number of Applicants", main = "Forecasts of Ratio of Accepted")
```

The forecasting plot shows that the ratio of accepted for London marathon in the next 10 years will generally remain constant. 

##### Checking ACF of the residuals

```{r}
# check autocorrelation function with lag from 1 to 20
acf(fc2$residuals, lag.max=20,main="ACF Check for Resisuals")
```

##### Box-Ljung test for residuals
```{r}
# Box-Ljung test
Box.test(fc2$residuals, lag=20, type="Ljung-Box")
```

##### Checking normality of the residuals
```{r}
# histogram of forecasterrors
plotForecastErrors(fc2$residuals)
```

#### Analysis of ratio of starters

##### Forecasting ratio of starters in next 10 years
```{r, fold.output=FALSE, fold.plot=FALSE}
ros <- london_marathon$`Ratio of Starters`
rosts <- ts(ros, ,frequency=1,start=1981)
rosts <- na.omit(rosts)
rostsarima <- auto.arima(rosts)
fc3 <- forecast(rostsarima, h=10)
plot(fc3,xlab = "Year", ylab= "Number of Applicants", main = "Forecasts of Ratio of Starters")
```

The forecasting plot shows that the ratio of accepted for London marathon in the next 10 years will decrease. 

##### Checking ACF of the residuals
```{r}
acf(fc3$residuals, lag.max=20,main="ACF Check for Resisuals")
```

##### Box-Ljung test for residuals
```{r}
Box.test(fc3$residuals, lag=20, type="Ljung-Box")
```

##### Checking normality of the residuals
```{r}
plotForecastErrors(fc3$residuals)
```


#### Analysis of ratio of finishers

##### Forecasting the ratio of finishers in next 10 years

```{r, fold.output=FALSE, fold.plot=FALSE}
rof <- london_marathon$`Ratio of Finishers`
rofts <- ts(rof, ,frequency=1,start=1981)
rofts <- na.omit(rofts)
roftsarima <- auto.arima(rofts)
fc4 <- forecast(roftsarima, h=10)
plot(fc4,xlab = "Year", ylab= "Number of Applicants", main = "Forecasts of Ratio of Finishers")

```

The forecasting plot shows that the ratio of finishers for London marathon in the next 10 years will remain constant. 

##### Checking ACF of the residuals
```{r}
acf(fc4$residuals, lag.max=20,main="ACF Check for Resisuals")

```

##### Box-Ljung test for residuals
```{r}
Box.test(fc4$residuals, lag=20, type="Ljung-Box")
```

##### Checking normality of the residuals

```{r}
plotForecastErrors(fc4$residuals)
```


Since the correlograms in models above show that none of the sample autocorrelations for lags 1-20 exceed the significance bounds, and the p-values for the Ljung-Box test are close to 1, we can conclude that there are very little evidences for non-zero autocorrelations in the forecast errors at lags 1-20.

The histograms of the time series show that the forecast errors are roughly normally distributed and the means seem to be close to zero. Therefore, it is plausible that the forecast errors are normally distributed with mean zero and constant variance.

Since successive forecast errors do not seem to be correlated, and the forecast errors seem to be normally distributed with means zeros and constant variances, the ARIMA(s) do seem to provide adequate predictive models for the dataset.

### Relating two data sets

To associate these two data sets, we start from the same field of year.
Now we can explore whether winning time is related to the number of finishers in that year.
We have reason to believe that the more finishers, the faster the winning time, due to the competitive nature of the elite.(hypothesis)

```{r}
filter_data2 <- london_marathon %>% filter(Year <= 2019)
winners_subset <- winners %>%
  select(Year, Time)
merged_data <- left_join(filter_data2, winners_subset, by = "Year")

correlation_coefficient <- cor(merged_data$Time, merged_data$Finishers, use = "complete.obs")
print(paste("Correlation Coefficient:", correlation_coefficient))
plot(merged_data$Finishers, merged_data$Time,
     xlab = "Number of Finishers",
     ylab = "Winning Time",
     main = "Relationship Between Finishers and Winning Time")
abline(lm(Time ~ Finishers, data = merged_data, na.action = na.exclude), col = "red")

```

Correlation Coefficient is  -0.493, the moderate negative correlation suggests that there is a tendency for winning time to decrease as the number of finishers increases.
The number of participants represents the size of the marathon, so can we assume that there is also a correlation between the number of participants and winning time?

```{r}
filter_data2 <- london_marathon %>% filter(Year <= 2019)
winners_subset <- winners %>%
  select(Year, Time)
merged_data <- left_join(filter_data2, winners_subset, by = "Year")

correlation_coefficient <- cor(merged_data$Time, merged_data$Applicants, use = "complete.obs")
print(paste("Correlation Coefficient:", correlation_coefficient))

plot(merged_data$Finishers, merged_data$Time,
     xlab = "Number of Applicants",
     ylab = "Winning Time",
     main = "Relationship Between Applicants and Winning Time")
abline(lm(Time ~ Finishers, data = merged_data, na.action = na.exclude), col = "red")

```

Correlation Coefficient is  -0.316, the mild to moderate negative correlation suggests that there is a tendency for winning time to decrease as the number of applicants increases.


## Clarification
Though there are some overlaps between our team members works, we came up the question independently and did the analysis independently. The report is an integration of our work. Here are the jobs that we did:

#### Longxiang Wu
data wrangling part  
winner dataset  
- plot of time versus year  
- boxplots of time based on category  
- analysis of difference of athletes’ performance based on nationality  
- analysis of difference between performance of men and women  
- summarising coutries that have the most winners  
london_marathon dataset  
- plots of variables(applicants,accepted,starters,finishers) versus year  
- creating and plots of new variables  
- linear models for the dataset  
- time series analysis and forecasting  
integrated team's works and composed report V1.0  


#### Navpreet Singh Sandhu 
introduction part  
winner dataset  
- analyzing trends in winning times over the year  
- comparing winning times between different categories  
- exploring potential correlations between winning times and other variables  
london_marathon dataset  
- creating new variables  


#### Shengle Yan
data wrangling part   
london_marathon dataset   
- Fill in the missing values of raised    
- Filter out the last two years of data in london_marathon    
- Create new variable   
Relating two data sets
- Analyze fundraising correlations with other data    
- Explore the correlation between two data sets   
- plot of Time versus Applicants    
- plot of Time versus Finishers   







